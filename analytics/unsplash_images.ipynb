{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224b3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from urllib.parse import urlencode\n",
    "from threading import Lock\n",
    "\n",
    "DEFAULT_URL_PARAMS = {\n",
    "    \"w\": \"1600\",\n",
    "    \"auto\": \"format\",\n",
    "}\n",
    "\n",
    "def _find_photos_file(dataset_dir: Path) -> Path:\n",
    "    candidates = list(dataset_dir.glob(\"photos.*\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\"No photos file found (expected photos.*)\")\n",
    "    return candidates[0]\n",
    "\n",
    "def download_unsplash_lite(\n",
    "    dataset_dir: str,\n",
    "    output_dir: str,\n",
    "    url_params: dict[str, str] | None = None,\n",
    "    max_workers: int = 8,\n",
    "    chunk_size: int = 500,\n",
    ") -> None:\n",
    "    dataset_dir = Path(dataset_dir).expanduser().resolve()\n",
    "    output_dir = Path(output_dir).expanduser().resolve()\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    photos_file = _find_photos_file(dataset_dir)\n",
    "    \n",
    "    params = DEFAULT_URL_PARAMS.copy()\n",
    "    if url_params:\n",
    "        params.update({k: str(v) for k, v in url_params.items()})\n",
    "    \n",
    "    print(f\"[INFO] Reading: {photos_file.name}\")\n",
    "    print(f\"[INFO] Processing in chunks of {chunk_size}\")\n",
    "    \n",
    "    # Thread-safe counters\n",
    "    stats = {\"ok\": 0, \"skipped\": 0, \"errors\": 0, \"processed\": 0}\n",
    "    stats_lock = Lock()\n",
    "    \n",
    "    def fetch(photo_id, base_url):\n",
    "        dest = output_dir / f\"{photo_id}.jpg\"\n",
    "        if dest.exists():\n",
    "            return \"skipped\", photo_id\n",
    "        \n",
    "        url = f\"{base_url}?{urlencode(params)}\"\n",
    "        try:\n",
    "            with requests.get(url, stream=True, timeout=20) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(dest, \"wb\") as f:\n",
    "                    for chunk in r.iter_content(1 << 14):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "            return \"ok\", photo_id\n",
    "        except Exception as e:\n",
    "            return \"error\", photo_id, str(e)\n",
    "    \n",
    "    def process_chunk(rows):\n",
    "        \"\"\"Process a chunk of rows with threading\"\"\"\n",
    "        if not rows:\n",
    "            return\n",
    "            \n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "            futures = [ex.submit(fetch, photo_id, url) for photo_id, url in rows]\n",
    "            for fut in as_completed(futures):\n",
    "                result = fut.result()\n",
    "                with stats_lock:\n",
    "                    stats[\"processed\"] += 1\n",
    "                    if result[0] == \"ok\":\n",
    "                        stats[\"ok\"] += 1\n",
    "                    elif result[0] == \"skipped\":\n",
    "                        stats[\"skipped\"] += 1\n",
    "                    else:\n",
    "                        stats[\"errors\"] += 1\n",
    "                        print(f\"[ERROR] {result[1]}: {result[2]}\")\n",
    "                    \n",
    "                    # Progress update every 100 images\n",
    "                    if stats[\"processed\"] % 100 == 0:\n",
    "                        print(f\"[PROGRESS] Processed {stats['processed']} images \"\n",
    "                              f\"(OK: {stats['ok']}, Skipped: {stats['skipped']}, Errors: {stats['errors']})\")\n",
    "    \n",
    "    # Stream CSV in chunks\n",
    "    try:\n",
    "        with open(photos_file, 'r', encoding='utf-8', newline='') as f:\n",
    "            # Detect delimiter from first line\n",
    "            first_line = f.readline()\n",
    "            f.seek(0)\n",
    "            delimiter = '\\t' if '\\t' in first_line else ','\n",
    "            \n",
    "            delim_name = 'TAB' if delimiter == '\\t' else 'COMMA'\n",
    "            print(f\"[INFO] Detected delimiter: {delim_name}\")\n",
    "            \n",
    "            reader = csv.DictReader(f, delimiter=delimiter)\n",
    "            \n",
    "            # Verify required columns exist\n",
    "            if not reader.fieldnames:\n",
    "                raise ValueError(\"Could not read CSV headers\")\n",
    "            \n",
    "            if 'photo_id' not in reader.fieldnames or 'photo_image_url' not in reader.fieldnames:\n",
    "                raise ValueError(f\"CSV must contain 'photo_id' and 'photo_image_url' columns. Found: {reader.fieldnames}\")\n",
    "            \n",
    "            print(f\"[INFO] Starting download...\")\n",
    "            \n",
    "            chunk = []\n",
    "            for i, row in enumerate(reader):\n",
    "                # Skip rows with missing data\n",
    "                if not row.get('photo_id') or not row.get('photo_image_url'):\n",
    "                    continue\n",
    "                    \n",
    "                chunk.append((row['photo_id'], row['photo_image_url']))\n",
    "                \n",
    "                if len(chunk) >= chunk_size:\n",
    "                    process_chunk(chunk)\n",
    "                    chunk = []\n",
    "            \n",
    "            # Process remaining rows\n",
    "            if chunk:\n",
    "                process_chunk(chunk)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to read CSV: {e}\")\n",
    "        raise\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Done.\")\n",
    "    print(f\"  Downloaded: {stats['ok']}\")\n",
    "    print(f\"  Skipped:    {stats['skipped']}\")\n",
    "    print(f\"  Errors:     {stats['errors']}\")\n",
    "    print(f\"  Total:      {stats['processed']}\")\n",
    "    print(f\"  Output:     {output_dir}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2191dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading: photos.csv000\n",
      "[INFO] Processing in chunks of 500\n",
      "[INFO] Detected delimiter: TAB\n",
      "[INFO] Starting download...\n",
      "[PROGRESS] Processed 100 images (OK: 100, Skipped: 0, Errors: 0)\n",
      "[PROGRESS] Processed 200 images (OK: 200, Skipped: 0, Errors: 0)\n",
      "[PROGRESS] Processed 300 images (OK: 300, Skipped: 0, Errors: 0)\n",
      "[PROGRESS] Processed 400 images (OK: 400, Skipped: 0, Errors: 0)\n",
      "[PROGRESS] Processed 500 images (OK: 500, Skipped: 0, Errors: 0)\n",
      "[PROGRESS] Processed 600 images (OK: 600, Skipped: 0, Errors: 0)\n",
      "[PROGRESS] Processed 700 images (OK: 700, Skipped: 0, Errors: 0)\n",
      "[PROGRESS] Processed 800 images (OK: 800, Skipped: 0, Errors: 0)\n",
      "[PROGRESS] Processed 900 images (OK: 900, Skipped: 0, Errors: 0)\n",
      "[PROGRESS] Processed 1000 images (OK: 1000, Skipped: 0, Errors: 0)\n",
      "[PROGRESS] Processed 1100 images (OK: 1100, Skipped: 0, Errors: 0)\n",
      "[ERROR] rsJtMXn3p_c: HTTPSConnectionPool(host='images.unsplash.com-grass-sun.jpg', port=443): Max retries exceeded with url: /?w=1600&auto=format (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x118b570d0>: Failed to resolve 'images.unsplash.com-grass-sun.jpg' ([Errno 8] nodename nor servname provided, or not known)\"))\n",
      "[PROGRESS] Processed 1200 images (OK: 1199, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 1300 images (OK: 1299, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 1400 images (OK: 1399, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 1500 images (OK: 1499, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 1600 images (OK: 1599, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 1700 images (OK: 1699, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 1800 images (OK: 1799, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 1900 images (OK: 1899, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 2000 images (OK: 1999, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 2100 images (OK: 2099, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 2200 images (OK: 2199, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 2300 images (OK: 2299, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 2400 images (OK: 2399, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 2500 images (OK: 2499, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 2600 images (OK: 2599, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 2700 images (OK: 2699, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 2800 images (OK: 2799, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 2900 images (OK: 2899, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 3000 images (OK: 2999, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 3100 images (OK: 3099, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 3200 images (OK: 3199, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 3300 images (OK: 3299, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 3400 images (OK: 3399, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 3500 images (OK: 3499, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 3600 images (OK: 3599, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 3700 images (OK: 3699, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 3800 images (OK: 3799, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 3900 images (OK: 3899, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 4000 images (OK: 3999, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 4100 images (OK: 4099, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 4200 images (OK: 4199, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 4300 images (OK: 4299, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 4400 images (OK: 4399, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 4500 images (OK: 4499, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 4600 images (OK: 4599, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 4700 images (OK: 4699, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 4800 images (OK: 4799, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 4900 images (OK: 4899, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 5000 images (OK: 4999, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 5100 images (OK: 5099, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 5200 images (OK: 5199, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 5300 images (OK: 5299, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 5400 images (OK: 5399, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 5500 images (OK: 5499, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 5600 images (OK: 5599, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 5700 images (OK: 5699, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 5800 images (OK: 5799, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 5900 images (OK: 5899, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 6000 images (OK: 5999, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 6100 images (OK: 6099, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 6200 images (OK: 6199, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 6300 images (OK: 6299, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 6400 images (OK: 6399, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 6500 images (OK: 6499, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 6600 images (OK: 6599, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 6700 images (OK: 6699, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 6800 images (OK: 6799, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 6900 images (OK: 6899, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 7000 images (OK: 6999, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 7100 images (OK: 7099, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 7200 images (OK: 7199, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 7300 images (OK: 7299, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 7400 images (OK: 7399, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 7500 images (OK: 7499, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 7600 images (OK: 7599, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 7700 images (OK: 7699, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 7800 images (OK: 7799, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 7900 images (OK: 7899, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 8000 images (OK: 7999, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 8100 images (OK: 8099, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 8200 images (OK: 8199, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 8300 images (OK: 8299, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 8400 images (OK: 8399, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 8500 images (OK: 8499, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 8600 images (OK: 8599, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 8700 images (OK: 8699, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 8800 images (OK: 8799, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 8900 images (OK: 8899, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 9000 images (OK: 8999, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 9100 images (OK: 9099, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 9200 images (OK: 9199, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 9300 images (OK: 9299, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 9400 images (OK: 9399, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 9500 images (OK: 9499, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 9600 images (OK: 9599, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 9700 images (OK: 9699, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 9800 images (OK: 9799, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 9900 images (OK: 9899, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 10000 images (OK: 9999, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 10100 images (OK: 10099, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 10200 images (OK: 10199, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 10300 images (OK: 10299, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 10400 images (OK: 10399, Skipped: 0, Errors: 1)\n",
      "[PROGRESS] Processed 10500 images (OK: 10499, Skipped: 0, Errors: 1)\n",
      "[ERROR] vigsqYux_-8: HTTPSConnectionPool(host='images.unsplash.com_thebeach.jpg', port=443): Max retries exceeded with url: /?w=1600&auto=format (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x118b7fe90>: Failed to resolve 'images.unsplash.com_thebeach.jpg' ([Errno 8] nodename nor servname provided, or not known)\"))\n",
      "[PROGRESS] Processed 10600 images (OK: 10598, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 10700 images (OK: 10698, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 10800 images (OK: 10798, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 10900 images (OK: 10898, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 11000 images (OK: 10998, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 11100 images (OK: 11098, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 11200 images (OK: 11198, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 11300 images (OK: 11298, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 11400 images (OK: 11398, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 11500 images (OK: 11498, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 11600 images (OK: 11598, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 11700 images (OK: 11698, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 11800 images (OK: 11798, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 11900 images (OK: 11898, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 12000 images (OK: 11998, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 12100 images (OK: 12098, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 12200 images (OK: 12198, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 12300 images (OK: 12298, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 12400 images (OK: 12398, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 12500 images (OK: 12498, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 12600 images (OK: 12598, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 12700 images (OK: 12698, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 12800 images (OK: 12798, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 12900 images (OK: 12898, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 13000 images (OK: 12998, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 13100 images (OK: 13098, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 13200 images (OK: 13198, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 13300 images (OK: 13298, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 13400 images (OK: 13398, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 13500 images (OK: 13498, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 13600 images (OK: 13598, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 13700 images (OK: 13698, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 13800 images (OK: 13798, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 13900 images (OK: 13898, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 14000 images (OK: 13998, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 14100 images (OK: 14098, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 14200 images (OK: 14198, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 14300 images (OK: 14298, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 14400 images (OK: 14398, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 14500 images (OK: 14498, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 14600 images (OK: 14598, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 14700 images (OK: 14698, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 14800 images (OK: 14798, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 14900 images (OK: 14898, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 15000 images (OK: 14998, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 15100 images (OK: 15098, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 15200 images (OK: 15198, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 15300 images (OK: 15298, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 15400 images (OK: 15398, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 15500 images (OK: 15498, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 15600 images (OK: 15598, Skipped: 0, Errors: 2)\n",
      "[PROGRESS] Processed 15700 images (OK: 15698, Skipped: 0, Errors: 2)\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "download_unsplash_lite(\n",
    "    dataset_dir=\"./unsplash-research-dataset-lite-latest\",\n",
    "    output_dir=\"./unsplash_raw_images\",\n",
    "    chunk_size=500,  # Process 1000 rows at a time\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b108099",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
